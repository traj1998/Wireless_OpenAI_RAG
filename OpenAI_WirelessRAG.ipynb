{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8bjMBTSOSnG",
        "outputId": "dc955547-4861-4405-dc43-470991bb1608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (3.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install Flask==3.0.0 pyngrok==7.1.2\n",
        "%pip install --quiet --upgrade langchain langchain-community langchain-pinecone\n",
        "%pip install -U --quiet tiktoken langchainhub langgraph langchain-text-splitters\n",
        "%pip install -qU langchain-openai\n",
        "!pip install --upgrade --upgrade-strategy eager \"regex\" \"charset-normalizer<4\" \"idna\" \"urllib3<3\" \"certifi\" \"requests\" \"anyio<5\" \"distro<2\" \"sniffio\" \"h11<0.15\" \"httpcore==1.*\"  \"annotated-types\" \"typing-extensions<5\" \"pydantic-core==2.27.1\" \"pydantic<3\" \"jiter<1\" \"tqdm\" \"colorama\" \"openai\" \"tiktoken\" \"httpx<0.28\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC2AmYxYbGoA"
      },
      "outputs": [],
      "source": [
        "port = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2OZWok0bJWY"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB_bICc5bpfI"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('NGROK_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uKG0jTCabL7n",
        "outputId": "b8049d38-3cbc-4601-e4c1-567ad2515292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://7549-34-134-86-113.ngrok-free.app'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "ngrok.set_auth_token(ngrok_token)\n",
        "ngrok.connect(port).public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPi69R5mGRFX"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from flask import Flask, request, jsonify\n",
        "import requests\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJJTTBpoHJh1"
      },
      "outputs": [],
      "source": [
        "##Langchain configuration\n",
        "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
        "LANGCHAIN_PROJECT=\"pr-gargantuan-whelp-32\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsSGJj6vGbif"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from flask import Flask, request, jsonify\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "import json\n",
        "import time\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "PINECONE_API_KEY = userdata.get(\"PINECONE_API_KEY\")\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index_name = userdata.get(\"PINECONE_INDEX_NAME\")\n",
        "\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,  # OpenAI embeddings are 1536 dimensions\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        time.sleep(1)\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Replace VertexAI with OpenAI components\n",
        "embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embedding_model)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Initialize OpenAI LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",  # or gpt-3.5-turbo\n",
        "    temperature=0,\n",
        "    max_retries=6,\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40LzYSyUw5mK"
      },
      "outputs": [],
      "source": [
        "@app.route('/api2', methods=['POST'])\n",
        "def handle_request12():\n",
        "    try:\n",
        "        # Parse the JSON request body\n",
        "        data = request.get_json()\n",
        "        print(data)\n",
        "        question = data.get('question')\n",
        "        context = data.get('data')\n",
        "        if not question or not context:\n",
        "            return jsonify({'error': 'Invalid input data'}), 400\n",
        "        print(question)\n",
        "        context = add_context(context)\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "         model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        # Send the question and context to the Gemini API\n",
        "        prompt = f\"Context: {context}\\nGiven the above context,  extract information from the context relevant to the question. Use the extracted information to answer the question. Justify your answer.\\n Question: {question}\\n\"\n",
        "        createContextEmbeddings(context)\n",
        "        rag_response = call_rag_model(prompt)\n",
        "        print(rag_response)\n",
        "        return jsonify({'answer': rag_response}), 200\n",
        "        #return jsonify({'answer': gemini_response.text.strip()}), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "\n",
        "\n",
        "#         raise Exception(f'Gemini API error: {response.status_code} {response.text}')\n",
        "\n",
        "app.run(port=port)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRkZ_d6iwzDR"
      },
      "outputs": [],
      "source": [
        "def add_context(context):\n",
        "  context['user_profile']['description of fields'] = json.dumps({\n",
        "                \"height_cm\": \"The height of the user in centimeters. Used for calculating metrics like BMI and other fitness indicators.\",\n",
        "                \"weight_kg\": \"The weight of the user in kilograms. Helps determine caloric needs and progress toward health goals.\",\n",
        "                \"target_steps\": \"The daily step count goal set by the user or system to encourage physical activity.\",\n",
        "                \"target_calories\": \"The daily target of calories to be burned through activity, critical for weight management goals.\"\n",
        "            }, indent = 2)\n",
        "  context['health_metrics']['description of fields'] = json.dumps({\n",
        "                \"heart_rate_bpm\": \"User's heart rate in beats per minute, an indicator of cardiovascular health and exercise intensity.\",\n",
        "                \"body_temperature_celsius\": \"The user's body temperature in Celsius, important for detecting illness or physiological changes.\",\n",
        "                \"steps_count\": \"The number of steps taken by the user during the current period. Tracks physical activity levels.\",\n",
        "                \"calories_burned\": \"The number of calories burned through activity and metabolic functions, reflecting energy expenditure.\",\n",
        "                \"blood_oxygen_percentage\": \"The oxygen saturation in the user's blood, a measure of respiratory and circulatory efficiency.\",\n",
        "                \"glucose_mg_dl\": \"Blood glucose levels in milligrams per deciliter, a key metric for metabolic health.\",\n",
        "                \"heart_rate_variability_ms\": \"Variability in the time between heartbeats, measured in milliseconds, indicating stress and recovery levels.\",\n",
        "                \"sleep_stages\": \"Sequence of sleep stages (e.g., Awake, REM, Deep) recorded during rest. Useful for sleep quality analysis.\",\n",
        "                \"blood_pressure\": \"The user's blood pressure in mmHg (systolic/diastolic), important for cardiovascular health monitoring.\"\n",
        "            }, indent = 2)\n",
        "  context['weather_data']['description of fields'] = json.dumps({\n",
        "            \"temperature_celsius\": \"The current temperature at the user's location in Celsius. Helps in activity planning and weather adaptation.\",\n",
        "            \"humidity_percentage\": \"The percentage of moisture in the air. Higher levels can affect comfort and exertion levels.\",\n",
        "            \"precipitation_mm\": \"The amount of precipitation in millimeters. Important for outdoor activity planning.\",\n",
        "            \"snowfall_mm\": \"The amount of snowfall in millimeters. Relevant for users in cold climates or outdoor winter sports.\",\n",
        "            \"air_quality_index\": \"An index representing air quality. Lower values signify healthier air for breathing.\",\n",
        "            \"air_quality_description\": \"Descriptive indicator of air quality (e.g., 'Good', 'Moderate'). Helps assess environmental conditions for activities.\",\n",
        "            \"uv_index\": \"The ultraviolet index at the location. Higher values indicate a greater need for sun protection.\",\n",
        "            \"wind_speed_ms\": \"The speed of wind in meters per second. Important for outdoor activities and comfort.\",\n",
        "            \"wind_gust_ms\": \"The maximum speed of wind gusts in meters per second. Helps anticipate extreme conditions.\",\n",
        "            \"pressure_hpa\": \"The atmospheric pressure in hectopascals. Sudden changes can indicate weather shifts.\"\n",
        "        }, indent = 2)\n",
        "  context['sensor_data']['description of fields'] = json.dumps( {\n",
        "            \"TMD3719 Ambient Light\": \"Measurement of ambient light intensity. Used for determining optimal brightness settings or light exposure levels.\",\n",
        "            \"Gravity Sensor\": \"Data on gravitational force along different axes. Useful for detecting orientation or movement patterns.\",\n",
        "            \"LSM6DSV Gyroscope-Uncalibrated\": \"Measures rotational motion in degrees per second. Useful for activity recognition or device orientation tracking.\",\n",
        "            \"Step Counter\": \"Tracks the total number of steps detected by the device. Core metric for activity monitoring.\",\n",
        "            \"Device Orientation\": \"Provides the current orientation of the device. Often used for navigation or activity context.\",\n",
        "            \"MMC56X3X Magnetometer\": \"Measures magnetic field strength. Used in navigation and determining magnetic direction.\",\n",
        "            \"LSM6DSV Accelerometer-Uncalibrated\": \"Measures acceleration along different axes. Useful for detecting movement or analyzing activity.\",\n",
        "            \"Orientation Sensor\": \"Tracks the device's pitch, roll, and yaw. Helpful for applications requiring precise motion tracking.\",\n",
        "            \"TMD3719 Proximity (wake-up)\": \"Detects proximity to nearby objects. Often used to trigger actions like wake-up events.\",\n",
        "            \"Linear Acceleration Sensor\": \"Measures linear acceleration excluding gravity. Useful for analyzing specific movements like jumps or runs.\",\n",
        "            \"LSM6DSV Gyroscope\": \"Measures angular velocity. Useful for analyzing rotation or angular motion.\",\n",
        "            \"Rotation Vector Sensor\": \"Combines accelerometer and gyroscope data to calculate device orientation in 3D space.\",\n",
        "            \"Game Rotation Vector Sensor\": \"Optimized for low latency, provides rotation data for gaming or real-time applications.\",\n",
        "            \"MMC56X3X Magnetometer-Uncalibrated\": \"Uncalibrated magnetic field data for advanced navigation or environmental sensing.\",\n",
        "            \"Auto Brightness\": \"Tracks changes in ambient brightness for dynamic screen adjustments.\",\n",
        "            \"Geomagnetic Rotation Vector Sensor\": \"Combines magnetic field data for orientation in magnetic environments.\",\n",
        "            \"Binned Brightness (wake-up)\": \"Histogram of brightness levels detected over time. Useful for light exposure analysis.\",\n",
        "            \"LSM6DSV Temperature\": \"Temperature of the gyroscope sensor. Helps in device calibration and thermal monitoring.\",\n",
        "            \"LSM6DSV Accelerometer\": \"Measures device acceleration. Useful for tracking movement dynamics.\",\n",
        "            \"VD6282 Rear Light Sensor\": \"Monitors light intensity on the device's rear side. Used for light adaptation or monitoring.\",\n",
        "            \"ICP20100 Pressure Sensor\": \"Measures atmospheric pressure. Relevant for weather monitoring and altitude detection.\",\n",
        "            \"ICP20100 Temperature\": \"Temperature data from the pressure sensor. Useful for environmental sensing.\",\n",
        "            \"Tilt Sensor (wake-up)\": \"Detects tilts to trigger actions like waking up the device or user.\"\n",
        "        }, indent = 2)\n",
        "  context['location']['description of fields'] = json.dumps({\n",
        "            \"latitude\": \"The user's current latitude in decimal degrees. Used for location-based services and context.\",\n",
        "            \"longitude\": \"The user's current longitude in decimal degrees. Combined with latitude to determine precise location.\"\n",
        "        }, indent = 2)\n",
        "  context['fitbit_data']['description of fields']  = json.dumps({\n",
        "        \"activities\": {\n",
        "            \"description\": \"A log of activities recorded by the Fitbit device.\"\n",
        "        },\n",
        "        \"summary\": {\n",
        "            \"caloriesOut\": {\n",
        "                \"description\": \"Total calories burned during the day.\"\n",
        "            },\n",
        "            \"activityCalories\": {\n",
        "                \"description\": \"Calories burned specifically through activities.\"\n",
        "            },\n",
        "            \"caloriesBMR\": {\n",
        "                \"description\": \"Calories burned through basic metabolic functions.\"\n",
        "            },\n",
        "            \"activeScore\": {\n",
        "                \"description\": \"A Fitbit-provided score for daily activity.\"\n",
        "            },\n",
        "            \"steps\": {\n",
        "                \"description\": \"Steps recorded by Fitbit during a tracked period.\"\n",
        "            },\n",
        "            \"floors\": {\n",
        "                \"description\": \"Number of floors climbed during the day.\"\n",
        "            },\n",
        "            \"elevation\": {\n",
        "                \"description\": \"Elevation gain during activities.\"\n",
        "            },\n",
        "            \"sedentaryMinutes\": {\n",
        "                \"description\": \"Minutes spent in sedentary behavior.\"\n",
        "            },\n",
        "            \"lightlyActiveMinutes\": {\n",
        "                \"description\": \"Minutes spent in light physical activity.\"\n",
        "            },\n",
        "            \"fairlyActiveMinutes\": {\n",
        "                \"description\": \"Minutes spent in moderate physical activity.\"\n",
        "            },\n",
        "            \"veryActiveMinutes\": {\n",
        "                \"description\": \"Minutes spent in vigorous physical activity.\"\n",
        "            },\n",
        "            \"distances\": {\n",
        "                \"description\": \"Distances traveled during different activity types.\"\n",
        "            },\n",
        "            \"marginalCalories\": {\n",
        "                \"description\": \"Additional calories burned through activities.\"\n",
        "            },\n",
        "            \"restingHeartRate\": {\n",
        "                \"description\": \"The user's resting heart rate.\"\n",
        "            },\n",
        "            \"heartRateZones\": {\n",
        "                \"description\": \"Heart rate zones recorded during the day.\"\n",
        "            }\n",
        "        },\n",
        "        \"goals\": {\n",
        "            \"caloriesOut\": {\n",
        "                \"description\": \"The target number of calories to burn daily.\"\n",
        "            },\n",
        "            \"steps\": {\n",
        "                \"description\": \"The target number of steps to achieve daily.\"\n",
        "            },\n",
        "            \"distance\": {\n",
        "                \"description\": \"The target distance to travel in kilometers.\"\n",
        "            },\n",
        "            \"floors\": {\n",
        "                \"description\": \"The target number of floors to climb daily.\"\n",
        "            },\n",
        "            \"activeMinutes\": {\n",
        "                \"description\": \"The target number of active minutes daily.\"\n",
        "            }\n",
        "        }\n",
        "    })\n",
        "  return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFfQFmikNOll"
      },
      "outputs": [],
      "source": [
        "def call_rag_model(question):\n",
        "  retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})\n",
        "  prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        Here is the user context data: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        Given the above context,  extract information from the context relevant to the question. Use the extracted information to answer the question. Justify your answer.\\n \"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "  rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "  )\n",
        "\n",
        "  response = rag_chain.invoke(question)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHgl3cNl8xmA"
      },
      "outputs": [],
      "source": [
        "##Creating the vector database of historical context and historical conversation embeddings\n",
        "# save the context with date and time of sensor data to allow it to predict user habits\n",
        "def storeEmbeddings(embedding, context):\n",
        "  embedding_id = str(uuid.uuid4())\n",
        "  index = pc.Index(index_name)\n",
        "  index.upsert([(embedding_id, embedding, context)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_zndsMy-NLM"
      },
      "outputs": [],
      "source": [
        "###Getting the historical Data and creating embedding\n",
        "import pandas as pd\n",
        "import uuid\n",
        "def createContextEmbeddings(data):\n",
        "  formatted_data = f\"\"\"\n",
        "  User Profile: Height: {data['user_profile']['height_cm']} cm, Weight: {data['user_profile']['weight_kg']} kg, Target Steps: {data['user_profile']['target_steps']}, Target Calories: {data['user_profile']['target_calories']}\n",
        "  User Profile description: {json.dumps(data['user_profile']['description of fields'])}\n",
        "  Health Metrics: {json.dumps(data['health_metrics'], indent=2)}\n",
        "  Weather Data: {json.dumps(data['weather_data'], indent=2)}\n",
        "  Sensor Data: {json.dumps(data['sensor_data'], indent=2)}\n",
        "  Fitbit data: {json.dumps(data['fitbit_data'], indent=2)}\n",
        "  Location: Latitude: {data['location']['latitude']}, Longitude: {data['location']['longitude']}\n",
        "  \"\"\"\n",
        "  formatted_dict = {'text':json.dumps({\n",
        "  'User Profile':  json.dumps(data['user_profile'], indent=2),\n",
        "  'Health Metrics': json.dumps(data['health_metrics'], indent=2),\n",
        "  'Weather Data': json.dumps(data['weather_data'], indent=2),\n",
        "  'Sensor Data': json.dumps(data['sensor_data'], indent=2),\n",
        "  'Location': json.dumps(data['location'], indent=2),\n",
        "  'Fitbit data': json.dumps(data['fitbit_data'], indent=2)})}\n",
        "  embedding = embedding_model.embed_query(formatted_data)\n",
        "  storeEmbeddings(embedding, formatted_dict)\n",
        "  return \"Finished Storing the embedding\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQD2Z4Q8cC-"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "#Reference: https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/#nodes-and-edges\n",
        "#Reference: https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/#create-index\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"user_data\",\n",
        "    \"This tool MUST be used. It retrieves relevant documents from the database.\",\n",
        ")\n",
        "\n",
        "tools = [retriever_tool]\n",
        "print(\"Tools List:\", tools)\n",
        "tool_output = retriever_tool.func(prompt)\n",
        "print(\"Retriever tool output:\", tool_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCfgIP8D8lXV"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, Sequence\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Literal\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The add_messages function defines how an update should be processed\n",
        "    # Default is to replace. add_messages says \"append\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5mwqR3Ew2EO"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    # Data model\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    # LLM\n",
        "    model = llm\n",
        "\n",
        "    # LLM with tool and validation\n",
        "    llm_with_tool = model.with_structured_output(grade)\n",
        "\n",
        "    # Prompt\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # Chain\n",
        "    chain = prompt | llm_with_tool\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "    print(docs)\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "\n",
        "    score = scored_result.binary_score\n",
        "\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"rewrite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsMazlI75umU"
      },
      "outputs": [],
      "source": [
        "def agent(state):\n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    model = llm\n",
        "    model = model.bind_tools([retriever_tool])\n",
        "    print(\"Tools bound to model:\", model)\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08gJT_456H5t"
      },
      "outputs": [],
      "source": [
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=f\"\"\" \\n\n",
        "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
        "    Here is the initial question:\n",
        "    \\n ------- \\n\n",
        "    {question}\n",
        "    \\n ------- \\n\n",
        "    Formulate an improved question: \"\"\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Grader\n",
        "    model = llm\n",
        "    response = model.invoke(msg)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRyIyHE36YzB"
      },
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "         dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    docs = last_message.content\n",
        "\n",
        "    # Prompt\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    # LLM\n",
        "    model = llm\n",
        "\n",
        "    # Post-processing\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Chain\n",
        "    rag_chain = prompt | model | StrOutputParser()\n",
        "\n",
        "    # Run\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "    return {\"messages\": [response]}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    return {\"documents\": web_results, \"question\": question}\n",
        "\n",
        "\n",
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to web search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"web_search\":\n",
        "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
        "        return \"web_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "fdn8VCGcu_Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "496fZWPB6vfn"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "workflow.add_node(\"agent\", agent)  # agent\n",
        "retrieve = ToolNode([retriever_tool])\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
        "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
        "workflow.add_node(\n",
        "    \"generate\", generate\n",
        ")  # Generating a response after we know the documents are relevant\n",
        "# Call agent node to decide to retrieve or not\n",
        "workflow.add_edge(START, \"agent\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    route_question,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    # Assess agent decision\n",
        "    grade_documents,\n",
        ")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "workflow.add_edge(\"rewrite\", \"agent\")\n",
        "\n",
        "# Compile\n",
        "graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8_TJT7w7-LT"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "input = f\"Context: {context}\\nGiven the above context,  extract information from the context and retrieve documents relevant to the question. Use the extracted information and retrieved documents to answer the question. Justify your answer.\\n Question: {question}\\n\"\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [\n",
        "        (\"user\", input),\n",
        "    ]\n",
        "}\n",
        "print(inputs)\n",
        "for output in graph.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint.pprint(f\"Output from node '{key}':\")\n",
        "        pprint.pprint(\"---\")\n",
        "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint.pprint(\"\\n---\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mybAYHtCd_hU"
      },
      "outputs": [],
      "source": [
        "##Multiquery Retriever\n",
        "from typing import List\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.output_parsers import OutputFixingParser\n",
        "\n",
        "# Set logging for the queries\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
        "\n",
        "# Output parser will split the LLM result into a list of queries\n",
        "class LineList(BaseModel):\n",
        "    # \"lines\" is the key (attribute name) of the parsed output\n",
        "    lines: List[str] = Field(description=\"Lines of text\")\n",
        "\n",
        "\n",
        "class LineListOutputParser(PydanticOutputParser):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__(pydantic_object=LineList)\n",
        "\n",
        "    def parse(self, text: str) -> LineList:\n",
        "        lines = text.strip().split(\"\\n\")\n",
        "        return LineList(lines=lines)\n",
        "\n",
        "\n",
        "output_parser = LineListOutputParser()\n",
        "new_parser = OutputFixingParser.from_llm(parser=output_parser, llm=llm)\n",
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from a vector\n",
        "    database. By generating multiple perspectives on the user question, your goal is to help\n",
        "    the user overcome some of the limitations of the distance-based similarity search.\n",
        "    Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\",\n",
        ")\n",
        "\n",
        "# Chain\n",
        "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=new_parser)\n",
        "multiqueryretriever = MultiQueryRetriever(\n",
        "    retriever=retriever, llm_chain=llm_chain, parser_key=\"lines\"\n",
        ")  # \"lines\" is the key (attribute name) of the parsed output\n",
        "print(prompt)\n",
        "unique_docs = multiqueryretriever.invoke(input=question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pd_wfiFeBrv"
      },
      "outputs": [],
      "source": [
        "from tavily import TavilyClient\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)\n",
        "def search_with_tavily(query, api_key, max_results=5):\n",
        "    try:\n",
        "        # Initialize the client\n",
        "        client = TavilyClient(api_key=userdata.get(\"TAVILY_API_KEY\"))\n",
        "\n",
        "        # Perform the search with parameters\n",
        "        response = client.search(\n",
        "            query=query,\n",
        "            max_results=max_results,\n",
        "            include_images=True,\n",
        "            search_depth=\"advanced\"\n",
        "        )\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nSearch Results for: {query}\\n\")\n",
        "        for result in response['results'][:1]:\n",
        "            print(f\"Title: {result['title']}\")\n",
        "            print(f\"Content: {result['content']}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}